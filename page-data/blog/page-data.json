{"componentChunkName":"component---src-pages-blog-tsx","path":"/blog/","result":{"data":{"allMdx":{"totalCount":1,"nodes":[{"id":"299d690f-b499-50fe-bdf9-80ee4c542505","fields":{"slug":"/blog/2024/efficient-llm-inference-with-limited-memory-by-apple/"},"frontmatter":{"title":"Efficient LLM Inference with Limited Memory by Apple","summary":"Apple's innovative approach to running large language models locally, using flash memory and dynamic parameter loading to exceed DRAM limitations.","date":"Sep 14, 2024","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#484858","images":{"fallback":{"src":"/static/206bb7b07ec9708aa019f377efa051c1/77b4b/efficient-llms.jpg","srcSet":"/static/206bb7b07ec9708aa019f377efa051c1/58451/efficient-llms.jpg 750w,\n/static/206bb7b07ec9708aa019f377efa051c1/f39cf/efficient-llms.jpg 1080w,\n/static/206bb7b07ec9708aa019f377efa051c1/77b4b/efficient-llms.jpg 1280w","sizes":"100vw"},"sources":[{"srcSet":"/static/206bb7b07ec9708aa019f377efa051c1/ee401/efficient-llms.webp 750w,\n/static/206bb7b07ec9708aa019f377efa051c1/de1b1/efficient-llms.webp 1080w,\n/static/206bb7b07ec9708aa019f377efa051c1/92bb1/efficient-llms.webp 1280w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5625}}}}}]}},"pageContext":{}},"staticQueryHashes":["3196427994"],"slicesMap":{}}